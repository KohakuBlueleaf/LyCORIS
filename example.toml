enable_conv = true
unet_target_module = [
  "Transformer2DModel", 
  "ResnetBlock2D", 
  "Downsample2D", 
  "Upsample2D",
]
unet_target_name = [
  "conv_in",
  "conv_out",
  "time_embedding.linear_1",
  "time_embedding.linear_2",
]
text_encoder_target_module = [
  "CLIPAttention",
  "CLIPMLP",
]
text_encoder_target_name = [
  "token_embedding", # not supported, Embedding module in CLIP
]

[module_algo_map]
  [module_algo_map.CrossAttention] #Attention Layer in UNet
    algo = "lora"
  [module_algo_map.FeedForward] #Attention Layer in UNet
    algo = "lokr"
  [module_algo_map.ResnetBlock2D]
    algo = "lora"